{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import experiment_util\n",
    "\n",
    "renaming_gold = {'essay_id': 'id', 'prediction_string': 'predictionstring'}\n",
    "renaming_pred = {'essay_id': 'id', 'prediction_string': 'predictionstring', 'discourse_type': 'class'}\n",
    "\n",
    "gold_df = pd.read_csv(\"merged.csv\")\n",
    "gold_df.rename(columns=renaming_gold, inplace=True)\n",
    "prediction_df = pd.read_csv(\"train1test2_prediction.csv\")\n",
    "prediction_df.rename(columns=renaming_pred, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv('clusters_effectivness.csv').set_index('id')\n",
    "gold_df = gold_df.join(clusters_df, on='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "gold_df_effective = gold_df[gold_df.discourse_effectiveness == 'Effective']\n",
    "gold_df_effective.to_csv('gold_effective.csv')\n",
    "gold_df_adequate = gold_df[gold_df.discourse_effectiveness == 'Adequate']\n",
    "gold_df_adequate.to_csv('gold_adequate.csv')\n",
    "gold_df_ineffective = gold_df[gold_df.discourse_effectiveness == 'Ineffective']\n",
    "gold_df_ineffective.to_csv('gold_ineffective.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation: 0.5544623497603323\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Lead': {'TP': 1673,\n  'FP': 699,\n  'FN': 619,\n  'Precision': 0.7299301919720768,\n  'Recall': 0.7053119730185498,\n  'F1': 0.717409948542024},\n 'Position': {'TP': 1965,\n  'FP': 1104,\n  'FN': 2060,\n  'Precision': 0.48819875776397514,\n  'Recall': 0.6402737047898338,\n  'F1': 0.5539892867211729},\n 'Claim': {'TP': 4118,\n  'FP': 4255,\n  'FN': 7860,\n  'Precision': 0.34379696109534147,\n  'Recall': 0.49181894183685654,\n  'F1': 0.4046975578595646},\n 'Evidence': {'TP': 7321,\n  'FP': 4649,\n  'FN': 4785,\n  'Precision': 0.6047414505204031,\n  'Recall': 0.6116123642439432,\n  'F1': 0.6081575012460542},\n 'Counterclaim': {'TP': 836,\n  'FP': 931,\n  'FN': 938,\n  'Precision': 0.47125140924464487,\n  'Recall': 0.4731182795698925,\n  'F1': 0.4721829991527817},\n 'Rebuttal': {'TP': 460,\n  'FP': 614,\n  'FN': 785,\n  'Precision': 0.36947791164658633,\n  'Recall': 0.42830540037243947,\n  'F1': 0.39672272531263475},\n 'Concluding Statement': {'TP': 2553,\n  'FP': 1108,\n  'FN': 799,\n  'Precision': 0.7616348448687351,\n  'Recall': 0.697350450696531,\n  'F1': 0.7280764294880936},\n 'overall': {'TP': 18926,\n  'FP': 13360,\n  'FN': 17846,\n  'Precision': 0.5146850864788426,\n  'Recall': 0.5861983522269715,\n  'F1': 0.5544623497603323}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_util.model_evaluate(prediction_df, gold_df)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation: 0.1195244716633719\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Rebuttal': {'TP': 60,\n  'FP': 1014,\n  'FN': 152,\n  'Precision': 0.2830188679245283,\n  'Recall': 0.055865921787709494,\n  'F1': 0.09331259720062209},\n 'Evidence': {'TP': 1610,\n  'FP': 10356,\n  'FN': 1547,\n  'Precision': 0.5099778270509978,\n  'Recall': 0.13454788567608222,\n  'F1': 0.2129207167889969},\n 'Claim': {'TP': 457,\n  'FP': 7878,\n  'FN': 1019,\n  'Precision': 0.30962059620596205,\n  'Recall': 0.05482903419316137,\n  'F1': 0.09316073794720212},\n 'Counterclaim': {'TP': 70,\n  'FP': 1697,\n  'FN': 136,\n  'Precision': 0.33980582524271846,\n  'Recall': 0.039615166949632144,\n  'F1': 0.07095793208312215},\n 'Position': {'TP': 140,\n  'FP': 2929,\n  'FN': 331,\n  'Precision': 0.29723991507430997,\n  'Recall': 0.045617464972303685,\n  'F1': 0.07909604519774012},\n 'Lead': {'TP': 186,\n  'FP': 2186,\n  'FN': 179,\n  'Precision': 0.5095890410958904,\n  'Recall': 0.07841483979763912,\n  'F1': 0.1359152356594812},\n 'Concluding Statement': {'TP': 321,\n  'FP': 3340,\n  'FN': 261,\n  'Precision': 0.5515463917525774,\n  'Recall': 0.08768096148593281,\n  'F1': 0.15130803676643884},\n 'overall': {'TP': 2844,\n  'FP': 29400,\n  'FN': 3625,\n  'Precision': 0.43963518318132633,\n  'Recall': 0.08820245627093412,\n  'F1': 0.1195244716633719}}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_util.model_evaluate(prediction_df.copy(), gold_df_ineffective.copy())[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation: 0.4020783330457223\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Lead': {'TP': 886,\n  'FP': 1486,\n  'FN': 359,\n  'Precision': 0.7116465863453815,\n  'Recall': 0.37352445193929174,\n  'F1': 0.489908764169201},\n 'Position': {'TP': 1394,\n  'FP': 1675,\n  'FN': 1391,\n  'Precision': 0.5005385996409336,\n  'Recall': 0.4542196155099381,\n  'F1': 0.4762555517594807},\n 'Claim': {'TP': 2271,\n  'FP': 6083,\n  'FN': 4827,\n  'Precision': 0.31994928148774304,\n  'Recall': 0.27184582236054583,\n  'F1': 0.29394253171110535},\n 'Evidence': {'TP': 3457,\n  'FP': 8508,\n  'FN': 2608,\n  'Precision': 0.5699917559769168,\n  'Recall': 0.28892603426661095,\n  'F1': 0.3834719911259013},\n 'Counterclaim': {'TP': 497,\n  'FP': 1270,\n  'FN': 654,\n  'Precision': 0.4317984361424848,\n  'Recall': 0.2812676853423882,\n  'F1': 0.3406442769019877},\n 'Concluding Statement': {'TP': 1554,\n  'FP': 2107,\n  'FN': 392,\n  'Precision': 0.7985611510791367,\n  'Recall': 0.42447418738049714,\n  'F1': 0.5543071161048689},\n 'Rebuttal': {'TP': 244,\n  'FP': 830,\n  'FN': 450,\n  'Precision': 0.3515850144092219,\n  'Recall': 0.2271880819366853,\n  'F1': 0.27601809954751133},\n 'overall': {'TP': 10303,\n  'FP': 21959,\n  'FN': 10681,\n  'Precision': 0.4909931376286695,\n  'Recall': 0.31935403880726554,\n  'F1': 0.4020783330457223}}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_util.model_evaluate(prediction_df.copy(), gold_df_adequate.copy())[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall evaluation: 0.275240039779121\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Lead': {'TP': 601,\n  'FP': 1771,\n  'FN': 83,\n  'Precision': 0.8786549707602339,\n  'Recall': 0.2533726812816189,\n  'F1': 0.3933246073298429},\n 'Position': {'TP': 431,\n  'FP': 2638,\n  'FN': 340,\n  'Precision': 0.5590142671854734,\n  'Recall': 0.14043662430759205,\n  'F1': 0.22447916666666667},\n 'Evidence': {'TP': 2254,\n  'FP': 9711,\n  'FN': 632,\n  'Precision': 0.781011781011781,\n  'Recall': 0.18838278311742582,\n  'F1': 0.30354858258703116},\n 'Claim': {'TP': 1390,\n  'FP': 6958,\n  'FN': 2016,\n  'Precision': 0.40810334703464474,\n  'Recall': 0.16650694777192143,\n  'F1': 0.236515228858261},\n 'Concluding Statement': {'TP': 678,\n  'FP': 2983,\n  'FN': 148,\n  'Precision': 0.8208232445520581,\n  'Recall': 0.18519530183010108,\n  'F1': 0.3022063739692445},\n 'Counterclaim': {'TP': 269,\n  'FP': 1498,\n  'FN': 150,\n  'Precision': 0.6420047732696897,\n  'Recall': 0.1522354272778721,\n  'F1': 0.24611161939615736},\n 'Rebuttal': {'TP': 156,\n  'FP': 918,\n  'FN': 185,\n  'Precision': 0.4574780058651026,\n  'Recall': 0.1452513966480447,\n  'F1': 0.22049469964664312},\n 'overall': {'TP': 5779,\n  'FP': 26477,\n  'FN': 3554,\n  'Precision': 0.6192006857387764,\n  'Recall': 0.17916046626984128,\n  'F1': 0.275240039779121}}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_util.model_evaluate(prediction_df.copy(), gold_df_effective.copy())[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def argument_similarity(arg1, arg2):\n",
    "    overlap = experiment_util.calc_overlap2(arg1, arg2)\n",
    "    return (overlap[0] + overlap[1]) / 2\n",
    "\n",
    "def mean_arg_similarity_per_selection(gold_df, selector = 'cluster', scnd_gold_df = None):\n",
    "    mean_similarities = dict()\n",
    "    overall_sum_similarity = 0\n",
    "    overall_comb_cnt = 0\n",
    "    for selection in list(set(gold_df[selector].values)):    # for each cluster/ label\n",
    "        gold_df_selection = gold_df[gold_df[selector] == selection]\n",
    "        dtext_tokens = [set(nltk.tokenize.word_tokenize(dt.lower())) for dt in gold_df_selection['discourse_text']]\n",
    "\n",
    "        if scnd_gold_df is not None:\n",
    "            gold_df_selection2 = scnd_gold_df[scnd_gold_df[selector] == selection]\n",
    "            dtext_tokens2 = [set(nltk.tokenize.word_tokenize(dt.lower())) for dt in gold_df_selection2['discourse_text']]\n",
    "            dt_combinations = list(itertools.product(dtext_tokens, dtext_tokens2))\n",
    "        else:\n",
    "            dt_combinations = list(itertools.combinations(dtext_tokens, 2))\n",
    "\n",
    "        mean_similarities[selection] = 0\n",
    "        for dt_combination in dt_combinations:\n",
    "            arg_similarity = argument_similarity(*dt_combination)\n",
    "            mean_similarities[selection] += arg_similarity\n",
    "            overall_sum_similarity += arg_similarity\n",
    "        mean_similarities[selection] /= len(dt_combinations)\n",
    "        overall_comb_cnt += len(dt_combinations)\n",
    "\n",
    "    print(\"⌀ =\", sum(mean_similarities.values()) / len(mean_similarities.values()))\n",
    "    print(\"⌀ w =\", overall_sum_similarity / overall_comb_cnt)\n",
    "    return mean_similarities\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.24430127782811323\n",
      "⌀ w = 0.24560972857694355\n"
     ]
    },
    {
     "data": {
      "text/plain": "{0: 0.25169242022060945,\n 1: 0.25455782861493287,\n 2: 0.25313766733720355,\n 3: 0.2583747008743779,\n 4: 0.2352838340681213,\n 5: 0.24758143377968708,\n 6: 0.26200629435921086,\n 7: 0.22942226953977315,\n 8: 0.25640722261962584,\n 9: 0.23277311562023165,\n 10: 0.23950458445840042,\n 11: 0.22229059349007965,\n 12: 0.22813990359879965,\n 13: 0.23625972233355036,\n 14: 0.2570875765070949}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_effective, 'cluster')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.2053458242229327\n",
      "⌀ w = 0.21246518520864516\n"
     ]
    },
    {
     "data": {
      "text/plain": "{0: 0.22362750001684178,\n 1: 0.20671682670867264,\n 2: 0.21620518637692557,\n 3: 0.20809666035516625,\n 4: 0.21523235890972903,\n 5: 0.16571891234235164,\n 6: 0.20284364402384214,\n 7: 0.2235217319625553,\n 8: 0.223254586060867,\n 9: 0.19420059497079784,\n 10: 0.19210338466929042,\n 11: 0.21177802592119369,\n 12: 0.16811738530463557,\n 13: 0.20704031002808967,\n 14: 0.2217302556930319}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_ineffective, 'cluster')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.216602131053382\n",
      "⌀ w = 0.22288490337981065\n"
     ]
    },
    {
     "data": {
      "text/plain": "{0: 0.22794852998568868,\n 1: 0.21828028333334443,\n 2: 0.22990613182679245,\n 3: 0.2232937745937118,\n 4: 0.21860529749103105,\n 5: 0.20588865310919355,\n 6: 0.22461596799223293,\n 7: 0.21524198178902512,\n 8: 0.23190302636508775,\n 9: 0.19423434632797623,\n 10: 0.21320458071064924,\n 11: 0.2054959614176357,\n 12: 0.1928133395688812,\n 13: 0.21462573370564986,\n 14: 0.23297435758383048}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_effective, 'cluster', gold_df_ineffective)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.2052113746886755\n",
      "⌀ w = 0.18915669370052202\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Position': 0.17996050112386375,\n 'Evidence': 0.239732057446455,\n 'Counterclaim': 0.18702506193153942,\n 'Lead': 0.22650087746831546,\n 'Rebuttal': 0.20682238842689385,\n 'Concluding Statement': 0.24822674068066608,\n 'Claim': 0.14821199574299493}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_effective, 'discourse_type')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.1628915935224877\n",
      "⌀ w = 0.18932930134348794\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Evidence': 0.20383239273108977,\n 'Counterclaim': 0.1352833438207233,\n 'Lead': 0.16041218362519372,\n 'Rebuttal': 0.1761502677411512,\n 'Concluding Statement': 0.19103374095322137,\n 'Position': 0.14313648827500547,\n 'Claim': 0.13039273751102903}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_ineffective, 'discourse_type')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⌀ = 0.1770725331138979\n",
      "⌀ w = 0.18665736111294243\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Position': 0.14952063127387055,\n 'Evidence': 0.2175248218370154,\n 'Counterclaim': 0.15257677447170728,\n 'Lead': 0.19207349944384555,\n 'Rebuttal': 0.18196125406175148,\n 'Concluding Statement': 0.2147805797090662,\n 'Claim': 0.1310701710000289}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arg_similarity_per_selection(gold_df_effective, 'discourse_type', gold_df_ineffective)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations([1,2,3,4], 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}